{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelwahabAdam/ID_card_ocr/blob/main/final_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mount your Google Drive into the runtime\n"
      ],
      "metadata": {
        "id": "euzEDl3a6sPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5G34uCrwIix",
        "outputId": "3ee26b7a-14df-4fee-b323-ecb03d99dc20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# change the working directory to the root directory of your Google Drive\n"
      ],
      "metadata": {
        "id": "k_Qhc4PB7LhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/mnt/Alexander_Til\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhZPCbXB7OCB",
        "outputId": "55b49999-3444-4cd5-ac1a-f7e073bef9ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mnt/Alexander_Til\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install all required packages|"
      ],
      "metadata": {
        "id": "_nGpMl6t7f6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jVHbpJcw3k6Z",
        "outputId": "b199b6bb-122e-48a6-d0b2-485c8202be58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2==2.12.1 (from -r requirements.txt (line 1))\n",
            "  Downloading pypdf2-2.12.1-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting textract==1.6.5 (from -r requirements.txt (line 2))\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.7)\n",
            "Collecting argcomplete~=1.10.0 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting six~=1.12.0 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract==1.6.5->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract==1.6.5->-r requirements.txt (line 2)) (2.4.1)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2)) (4.3)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract==1.6.5->-r requirements.txt (line 2)) (4.9.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract==1.6.5->-r requirements.txt (line 2)) (8.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract==1.6.5->-r requirements.txt (line 2))\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2)) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract==1.6.5->-r requirements.txt (line 2)) (2023.3)\n",
            "Building wheels for collected packages: docx2txt, python-pptx, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3957 sha256=fe38d1b4e62a174c5678a3c6f9e645b2424a72509df656934d7113ae04eef36b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=81353c136dbc96e4665ea06d0b650f114d60996e2f0e7a89d08085eaf110c774\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=3a6c845808a76386e99d6c8b69d91cf5d4bfb4bbbf7d181b78e1ac954c73cc5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=db3054f3ee710ab2f54a75b4f059acb21b18152d15ab261517f3ac92bcc7ded6\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt python-pptx compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, PyPDF2, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.18 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-2.12.1 SpeechRecognition-3.8.1 XlsxWriter-3.1.2 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.18.0 python-pptx-0.6.21 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "# !apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils \\\n",
        "#      pstotext tesseract-ocr \\\n",
        "#      flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libasound2-dev libpulse-dev\n",
        "# !apt-get install libasound2-dev\n",
        "# !apt remove tesseract-ocr\n",
        "!apt install tesseract-ocr\n",
        "!apt install tesseract-ocr-deu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPgkuqSUEI7R",
        "outputId": "06f165e5-7a87-4307-c191-3c63e73c8fec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,014 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,063 kB]\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease [24.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,359 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,803 kB]\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,400 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,538 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal/main amd64 Packages [41.1 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,282 kB]\n",
            "Fetched 14.9 MB in 4s (3,886 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 3s (1,816 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-deu\n",
            "0 upgraded, 1 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 745 kB of archives.\n",
            "After this operation, 1,540 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-deu all 1:4.00~git30-7274cfa-1 [745 kB]\n",
            "Fetched 745 kB in 2s (410 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-deu.\n",
            "(Reading database ... 123116 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-deu_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-deu (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-deu (1:4.00~git30-7274cfa-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4fDzaukvSD1"
      },
      "source": [
        "## Defining the required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0fC0EVtavSD2"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "import textract\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "from typing import Optional, Sequence, Union, List, Tuple\n",
        "from typing import TypeVar, Callable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NOS-3eZvSD3"
      },
      "source": [
        "### Defining the main Class init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qf2hYUK8vSD3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ExtractFromDoc:\n",
        "    def __init__(self, pdf_path: Optional[str] = 'src', out_path: Optional[str] = 'res', threshold_doc: Optional[dict] = {}, threshold: Optional[float] = 0.8) -> None:\n",
        "        self.final_output = {}\n",
        "        self.output = {}\n",
        "        self.threshold_doc = threshold_doc\n",
        "        self.threshold = threshold\n",
        "        self.pdf_path=pdf_path\n",
        "        # self.main()\n",
        "\n",
        "    def extract_text(self, path:str) -> Tuple[str, int]:\n",
        "        # Extract text using Textract\n",
        "        text = textract.process(path, method='tesseract', language='deu')\n",
        "        return text.decode('utf-8'),0\n",
        "\n",
        "    def read_pdf_split_images(self) -> None:\n",
        "        ## This method search for pdf file in src directory, and extract images from it.\n",
        "        directory = self.pdf_path\n",
        "        print(os.listdir(os.path.join(os.curdir,directory)))\n",
        "        for filename in os.listdir(os.path.join(os.curdir,directory)):\n",
        "            if filename.endswith('.pdf'):\n",
        "                ids =0\n",
        "                reader = PdfReader(os.path.join(os.curdir,directory,filename))\n",
        "                for page in reader.pages:\n",
        "                    for image in page.images:\n",
        "                        with open(f\"res/id_{ids}.jpg\", \"wb\") as fp:\n",
        "                            fp.write(image.data)\n",
        "                    ids+=1\n",
        "\n",
        "    def clear_field_new(self, var:str, *field: Sequence[str]) -> str:\n",
        "        ## This method clear output string and remove any static words or characters.\n",
        "        val = ''.join(var)\n",
        "        for i in field:\n",
        "            val = val.replace(i, '')\n",
        "        val = val.strip()\n",
        "        return val\n",
        "\n",
        "    def get_src_images(self)-> List[str]:\n",
        "        ## This method get all src images from res directory.\n",
        "        return  glob.glob(os.path.join('res', \"*.jpg\"))\n",
        "\n",
        "    def get_temp_images(self,path:str)-> List[str]:\n",
        "        ## This method get all temp images from path (input arg) directory.\n",
        "        return glob.glob(os.path.join(path,  \"*.png\"))\n",
        "\n",
        "    def crop_image_and_detect_text(self):\n",
        "        ## This method read all cropped images and extract text from them.\n",
        "        self.output['res'] = {}\n",
        "        cropped_images = glob.glob(os.path.join(f'res','detection',  \"*.png\"))\n",
        "        for sup_image_path in cropped_images:\n",
        "            sup_image_name = sup_image_path.split('/')[-1].replace('.png', '') ###TODO CHANGE \\\\ TO /\n",
        "            if 'res' not in sup_image_name:\n",
        "                text, confidence = self.extract_text(sup_image_path)\n",
        "                self.output['res'][sup_image_name] =  {'value':text, 'confidence':0}   ##text\n",
        "\n",
        "    def add_data_to_output(self) -> None:\n",
        "      ## This method clean the extracted (OCR) text and store it in final_output dict.\n",
        "        self.final_output['res'] = {}\n",
        "        # print(\"********************************\")\n",
        "        # print(f'self.output: {self.output}')\n",
        "        # print(\"********************************\")\n",
        "        for val in self.output['res']:\n",
        "            if 'birth' in val :\n",
        "                name_var = re.sub(r\"[^0-9.]\", \"\", self.output['res'][val]['value'])\n",
        "                self.final_output['res']['birth'] = {'value':name_var}\n",
        "\n",
        "            if 'expirty' in val :\n",
        "                name_var = re.sub(r\"[^0-9.]\", \"\", self.output['res'][val]['value'])\n",
        "                self.final_output['res']['expirty'] = {'value':name_var}\n",
        "\n",
        "            if 'startDat' in val :\n",
        "                name_var = re.sub(r\"[^0-9.]\", \"\", self.output['res'][val]['value'])\n",
        "                self.final_output['res']['startDat'] = {'value':name_var}\n",
        "\n",
        "            if 'Fname' in val :\n",
        "                cleaned_string = re.sub(r\"[\\r\\n\\t\\x0c]\", \"\", self.output['res'][val]['value'])\n",
        "                name_var = self.clear_field_new(cleaned_string,'Name', 'Surname', 'Nom','/',',','Geburts','name','at birth','naissance').strip()\n",
        "                self.final_output['res']['Fname'] = {'value':name_var}\n",
        "\n",
        "            if 'Secname' in val :\n",
        "                cleaned_string = re.sub(r\"[\\r\\n\\t\\x0c]\", \"\", self.output['res'][val]['value'])\n",
        "                name_var = self.clear_field_new(cleaned_string, 'Given', 'names','/',',','Vornamen','vornamen','Prenoms','prenoms','prénom','Prénom').strip()\n",
        "                if len(name_var.split(' ')) > 1:\n",
        "                    name_var = name_var.split(' ')[-1]\n",
        "                self.final_output['res']['Sname'] = {'value':name_var}\n",
        "\n",
        "            if 'serialNum' in val :\n",
        "                cleaned_string = re.sub(r\"[\\r\\n\\t\\x0c]\", \"\", self.output['res'][val]['value'])\n",
        "                name_var = self.clear_field_new(cleaned_string, 'BUNDESREPUBLIK', 'DEUTSCHLAND','/',',','|').strip().split(' ')\n",
        "                filtered_list = [item for item in name_var if len(item) > 5]\n",
        "                if filtered_list:\n",
        "                    self.final_output['res']['serialNum'] = {'value':filtered_list[-1]}\n",
        "                else:\n",
        "                    self.final_output['res']['serialNum'] = {'value':''}\n",
        "\n",
        "    def get_output(self) -> None:\n",
        "        ## This method write the output.json file\n",
        "        for page in self.final_output:\n",
        "            with open(f\"{os.path.join('res','output.json')}\", 'w', encoding='utf8') as json_file:\n",
        "                json.dump(self.final_output[page],\n",
        "                        json_file, ensure_ascii=False)\n",
        "                print(f\"Output: res/output.json\")\n",
        "\n",
        "    def detect_id_and_split(self) -> None:\n",
        "      ## This method is the core of all script, it detect id images and find the match from temp\n",
        "\n",
        "        docs_images = self.get_src_images()     ### Read src directory and get images path as list\n",
        "        if not docs_images:\n",
        "            print(\"src directory is empty\")\n",
        "            print(\"The pdf is empty!\")\n",
        "            print(\"Terminating the Script\")\n",
        "            sys.exit()\n",
        "\n",
        "        # ### Create res/sup-diectories to divide src\n",
        "        dir_to_creat = ['detection']\n",
        "        for file in dir_to_creat:\n",
        "            if not os.path.exists(os.path.join('res',file)):\n",
        "                os.makedirs(os.path.join('res',file))\n",
        "\n",
        "        ### loop on src images.\n",
        "        for doc_image_path in docs_images:\n",
        "            ### Remove full path and extension > /src/page1_elec.png >> page1_elec.\n",
        "            name = doc_image_path.split('/')[-1].replace('.jpg', '')\n",
        "            # Read input src image using opencv.\n",
        "            temp_image = cv2.imread(doc_image_path)\n",
        "\n",
        "            # Resize input src image using opencv.\n",
        "            # doc_image = cv2.resize(temp_image, (1960, 2824))\n",
        "            doc_image = temp_image\n",
        "\n",
        "            # Convert to gray scale >> because some Images as colored and to enhance detection.\n",
        "            gray_doc_image = cv2.cvtColor(doc_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Get template Images.\n",
        "            temp_images = self.get_temp_images(path='temp')\n",
        "\n",
        "            # Add some flags to better customize the loop\n",
        "            # To draw and extract the first Image found (Only exist once in the doc).\n",
        "            done_Fname = False\n",
        "            done_Secname = False\n",
        "            done_serialNumb = False\n",
        "            done_Enddate = False\n",
        "            done_birth = False\n",
        "            done_startDate = False\n",
        "            # Loop of each template file to find matches with threshold >>> IMPORTANT\n",
        "            for temp_image in temp_images:\n",
        "                # Load the template image and the target image.\n",
        "                template_img = cv2.imread(temp_image)\n",
        "                gray_template_img = cv2.cvtColor(\n",
        "                    template_img, cv2.COLOR_BGR2GRAY)\n",
        "                # Get the dimensions of the template image.\n",
        "                template_height, template_width = gray_template_img.shape[:2]\n",
        "                # Perform template matching.\n",
        "                result = cv2.matchTemplate(\n",
        "                    gray_doc_image, gray_template_img, cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "                # Define a threshold value to consider a match.\n",
        "                temp_temp = temp_image.split('/')[-1].split('_')[:-1][0]               ###TODO CHANGE \\\\ TO /\n",
        "                threshold = self.threshold_doc.get(temp_temp, self.threshold)\n",
        "\n",
        "                # Get the location of the matches\n",
        "                locations = list(zip(*np.where(result >= threshold)))\n",
        "                # Draw rectangles around the matches.\n",
        "                for loc in locations:\n",
        "                    top_left_corner = loc[::-1]\n",
        "                    bottom_right_corner = (\n",
        "                        top_left_corner[0] + template_width, top_left_corner[1] + template_height)\n",
        "                    if 'Secname' in temp_image and done_Fname == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+40 ,\n",
        "                                            top_left_corner[0]:bottom_right_corner[0]+50]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "\n",
        "                            self.write_threshold(img=img,thresh=False,img_name='Secname',name=name)\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_Secname.png'), img)\n",
        "\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0], top_left_corner[1]),\n",
        "                                        (bottom_right_corner[0]+50, bottom_right_corner[1]+40),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_Fname = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "                    if 'Fname' in temp_image and done_Secname == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+50 ,\n",
        "                                            top_left_corner[0]:bottom_right_corner[0]+width]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "\n",
        "                            self.write_threshold(img=img,thresh=False,img_name='Fname',name=name)\n",
        "\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_Fname.png'), img)\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0], top_left_corner[1]),\n",
        "                                        (bottom_right_corner[0]+width, bottom_right_corner[1]+50),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_Secname = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "                    if 'startDate' in temp_image and done_startDate == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+50 ,\n",
        "                                            top_left_corner[0]:bottom_right_corner[0]+50]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "                            self.write_threshold(img=img,thresh=False,img_name='startDat',name=name)\n",
        "\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_startDat.png'), img)\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0], top_left_corner[1]),\n",
        "                                        (bottom_right_corner[0]+50, bottom_right_corner[1]+50),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_startDate = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "                    if 'birth' in temp_image and done_birth == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+50 ,\n",
        "                                            top_left_corner[0]-70:bottom_right_corner[0]+25]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "\n",
        "                            self.write_threshold(img=img,thresh=False,img_name='birth',name=name)\n",
        "\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_birth.png'), img)\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0]-70, top_left_corner[1]),\n",
        "                                        (bottom_right_corner[0]+25, bottom_right_corner[1]+50),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_birth = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "                    if 'expirty' in temp_image and done_Enddate == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+40 ,\n",
        "                                            top_left_corner[0]-70:bottom_right_corner[0]+25]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "\n",
        "                            self.write_threshold(img=img,thresh=False,img_name='expirty',name=name)\n",
        "\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_expirty.png'), img)\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0]-70, top_left_corner[1]),\n",
        "                                        (bottom_right_corner[0]+25, bottom_right_corner[1]+40),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_Enddate = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "                    if 'serialNum' in temp_image and done_serialNumb == False:\n",
        "                            height = doc_image.shape[0]\n",
        "                            width = doc_image.shape[1]\n",
        "                            img = doc_image[top_left_corner[1]:bottom_right_corner[1]+15 ,\n",
        "                                            top_left_corner[0]:int(width)]\n",
        "\n",
        "                            name = name.split('\\\\')[-1]\n",
        "                            self.write_threshold(img=img,thresh=True,img_name='serialNum',name=name)\n",
        "\n",
        "\n",
        "                            # cv2.imwrite(os.path.join('res','detection',f'{name}_serialNum.png'), img)\n",
        "                            cv2.rectangle(doc_image,\n",
        "                                        (top_left_corner[0], top_left_corner[1]),\n",
        "                                        (int(width), bottom_right_corner[1]+15),\n",
        "                                        (0, 255, 0), 2)\n",
        "                            done_serialNumb = True\n",
        "                            cv2.imwrite(os.path.join('res','detection',f'{name}_res.png'), doc_image)\n",
        "                            # matching = 'done'\n",
        "                            break\n",
        "\n",
        "    def write_threshold(self, img: np.ndarray, name: str, img_name: str, thresh: int) -> None:\n",
        "        ## This method make threshold for images with multi color (such as: serial id)\n",
        "\n",
        "        threshold_value = 100\n",
        "        max_value = 255\n",
        "\n",
        "        # Set the thresholding type to cv2.THRESH_BINARY_INV\n",
        "        threshold_type = cv2.THRESH_BINARY_INV\n",
        "\n",
        "        if thresh:\n",
        "            ret, thresholded_img = cv2.threshold(img, threshold_value, max_value, threshold_type)\n",
        "            cv2.imwrite(os.path.join('res','detection',f'{name}_{img_name}.png'), thresholded_img)\n",
        "        else:\n",
        "            cv2.imwrite(os.path.join('res','detection',f'{name}_{img_name}.png'), img)\n",
        "\n",
        "    def main(self) -> None:\n",
        "        ## This is the main method\n",
        "        print(\"Start Main\")\n",
        "        self.read_pdf_split_images()\n",
        "        self.detect_id_and_split()\n",
        "        self.crop_image_and_detect_text()\n",
        "        self.add_data_to_output()\n",
        "        self.get_output()\n",
        "        print(\"End Main\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vjEsz9yvSD5"
      },
      "source": [
        "### Run the script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT-52NHvvSD6",
        "outputId": "2d5c0b4e-724f-42ea-8922-f0713dbde3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Main\n",
            "['id_card2.pdf']\n",
            "Output: res/output.json\n",
            "End Main\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "    ### You have to put the temp directory next to the script.\n",
        "    ### The result will be in res directory.\n",
        "    ExtractFromDoc(\n",
        "            threshold_doc={\n",
        "                'birth': 0.8,\n",
        "                'expirty': 0.8,\n",
        "                'Fname': 0.8,\n",
        "                'Secname': 0.8,\n",
        "                'serialNum': 0.8,\n",
        "                'startDate': 0.8,\n",
        "                },\n",
        "            threshold=0.8,\n",
        "            pdf_path='src',\n",
        "            out_path='res'\n",
        "            ).main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}